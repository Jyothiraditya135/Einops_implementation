{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeF3UQHt0WgOBTkFBvKby6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyothiraditya135/Einops_implementation/blob/main/Einops_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The implementation"
      ],
      "metadata": {
        "id": "IdPatfpccg2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary imports\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Union, Tuple, Dict"
      ],
      "metadata": {
        "id": "EKny69WCqujn"
      },
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_implicit_axes(input_shape: List[int],\n",
        "                           left_str: str,\n",
        "                           params: Dict[str, int]) -> Dict[str, int] :\n",
        "    \"\"\"\n",
        "    The function identifies axes that are to be inferred from the shape of the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    left_dim_ltrs = re.findall(r'\\(.*?\\)|\\S+', left_str)\n",
        "\n",
        "    map_ltrs_dims = {}\n",
        "    for ax in params:\n",
        "        map_ltrs_dims[ax] = params[ax]\n",
        "\n",
        "    ell_len = 0\n",
        "\n",
        "    for i, a in enumerate(left_dim_ltrs):\n",
        "\n",
        "        i = i + ell_len\n",
        "\n",
        "        if a in map_ltrs_dims.keys():\n",
        "          raise ValueError(f\"Indexing expression contains duplicate dimension {a}\")\n",
        "\n",
        "        if a.startswith('('):\n",
        "          a = a.strip('()').split()\n",
        "          missing_ltr = None\n",
        "          prod = 1\n",
        "\n",
        "          for key in a:\n",
        "            if '(' in key or ')' in key:\n",
        "                raise ValueError(\"Brackets inside brackets not allowed\")\n",
        "            if key not in params:\n",
        "              missing_ltr = key\n",
        "            else:\n",
        "              prod *= params[key]\n",
        "\n",
        "          if missing_ltr is not None:\n",
        "              missing_dim = input_shape[i] // prod\n",
        "              map_ltrs_dims[missing_ltr] = missing_dim\n",
        "\n",
        "    return map_ltrs_dims"
      ],
      "metadata": {
        "id": "FT8q9ldw66t3"
      },
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_parse(pattern: str) -> List[str]:\n",
        "\n",
        "    parsed = re.findall(r\"\\([^()]+\\)|\\S+\", pattern)\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    for el in parsed:\n",
        "        if el.startswith(\"(\") and el.endswith(\")\"):\n",
        "            tokens.append(el[1:-1].split())\n",
        "        else:\n",
        "            tokens.append(el)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "gAqBM3qxrGif"
      },
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(tokens: List[str]) -> List[str]:\n",
        "    flat = []\n",
        "    for token in tokens:\n",
        "        if isinstance(token, list):\n",
        "            flat.extend(token)\n",
        "        else:\n",
        "            flat.append(token)\n",
        "    return flat"
      ],
      "metadata": {
        "id": "k_4rnHCNrgZR"
      },
      "execution_count": 516,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repl(match: re.Match) -> str:\n",
        "        dots = match.group(0)\n",
        "        if dots != '...':\n",
        "           raise ValueError(f\"Invalid ellipsis sequence encountered: {dots}\")\n",
        "        else:\n",
        "            return '...'\n",
        "\n",
        "tok = \"...\"\n",
        "re.sub(r'\\.+', repl, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bkQk_-qrxvK_",
        "outputId": "5f2bf5d2-c23c-4e64-8be3-53cafbc470dd"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 517
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def substitute_ellipsis(flat_tokens: List[str], rank: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    If an ellipsis (\"...\") is present in the flat token list, substitute it with placeholder tokens.\n",
        "    For example, if rank = 5 and there are 2 explicit tokens, then the ellipsis is replaced by 3 tokens: [_e0, _e1, _e2]\n",
        "    \"\"\"\n",
        "\n",
        "    if flat_tokens.count('...') > 1:\n",
        "        raise ValueError(\"More than one ellipsis in pattern!\")\n",
        "\n",
        "    if '...' in flat_tokens:\n",
        "        pos = flat_tokens.index(\"...\")\n",
        "        other_toks = [tok for tok in flat_tokens if tok != \"...\"]\n",
        "        num_placeholders = rank - len(other_toks)\n",
        "\n",
        "        if num_placeholders < 0:\n",
        "            raise ValueError(\"More explicit tokens than tensor rank!\")\n",
        "\n",
        "        placeholders = [f\"_e{i}\" for i in range(num_placeholders)]\n",
        "\n",
        "        return (flat_tokens[:pos] + placeholders + flat_tokens[pos+1:]), placeholders\n",
        "\n",
        "    return flat_tokens, []"
      ],
      "metadata": {
        "id": "_D3YGaq1u-49"
      },
      "execution_count": 518,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_axis_name(name: str) -> bool:\n",
        "    return re.fullmatch(r\"[a-zA-Z_][a-zA-Z0-9_]*\", name)\n",
        "\n",
        "def validate_tokens(tokens: List[str]):\n",
        "    for token in tokens:\n",
        "        if not is_valid_axis_name(token):\n",
        "            raise ValueError(f\"Invalid axis identifier: '{token}'\")"
      ],
      "metadata": {
        "id": "5jF1AoWpbQhP"
      },
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_pattern(pattern: str) -> Tuple[List[str], List[str]]:\n",
        "\n",
        "    if '->' not in pattern:\n",
        "        raise ValueError(\"Pattern must contain '->'\")\n",
        "\n",
        "    left_str, right_str = pattern.split(\"->\")\n",
        "\n",
        "    left_tokens = tokenize_and_parse(left_str.strip())\n",
        "    right_tokens = tokenize_and_parse(right_str.strip())\n",
        "\n",
        "    return left_tokens, right_tokens"
      ],
      "metadata": {
        "id": "PHlRvMCOre0y"
      },
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repl(match: re.Match) -> str:\n",
        "        dots = match.group(0)\n",
        "        if dots != '...':\n",
        "           raise ValueError(f\"Invalid ellipsis sequence encountered: {dots}\")\n",
        "        else:\n",
        "            return '...'"
      ],
      "metadata": {
        "id": "UIyZyPAu0caX"
      },
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_steps(left_tokens: List[str],\n",
        "                    right_tokens: List[str],\n",
        "                    input_shape: List[int],\n",
        "                    params: Dict[str, int]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    The function helps determine the steps to be taken based on the parsed pattern, to reach the required output.\n",
        "\n",
        "    Steps (applied in order):\n",
        "      1. Split (de-merge) operations from groups on the left.\n",
        "      2. Transpose of the \"common\" tokens to match the order in the right side.\n",
        "      3. Repeat (insertion) operations for tokens that exist on the right but not the left.\n",
        "         The step now includes the output axis at which to insert the new axis.\n",
        "      4. Merge operations for grouped tokens on the right.\n",
        "    \"\"\"\n",
        "\n",
        "    steps = []\n",
        "    axes_after_split = []\n",
        "\n",
        "    for tok in left_tokens:\n",
        "        if \".\" in tok:\n",
        "            re.sub(r'\\.+', repl, tok)\n",
        "\n",
        "    for tok in right_tokens:\n",
        "        if \".\" in tok:\n",
        "            re.sub(r'\\.+', repl, tok)\n",
        "\n",
        "    if '...' in left_tokens:\n",
        "\n",
        "        left_tokens_mod, placeholders = substitute_ellipsis(left_tokens, rank=len(input_shape))\n",
        "\n",
        "        right_tokens_mod = []\n",
        "        for i, tok in enumerate(right_tokens):\n",
        "            if \"...\" in tok:\n",
        "                pos = i\n",
        "                if isinstance(tok, list):\n",
        "                    right_tokens_mod.extend(right_tokens[:pos])\n",
        "                    right_tokens_mod.append(placeholders)\n",
        "                    right_tokens_mod.extend(right_tokens[pos+1:])\n",
        "                else:\n",
        "                    right_tokens_mod = right_tokens[:pos] + placeholders + right_tokens[pos+1:]\n",
        "\n",
        "        left_flat = flatten(left_tokens_mod)\n",
        "        right_flat = flatten(right_tokens_mod)\n",
        "\n",
        "        left_tokens = left_tokens_mod\n",
        "        right_tokens = right_tokens_mod\n",
        "\n",
        "    else:\n",
        "        left_flat = flatten(left_tokens)\n",
        "        right_flat = flatten(right_tokens)\n",
        "\n",
        "    if(len(left_tokens) != len(input_shape)):\n",
        "        raise ValueError(f\"Wrong shape: expected {len(left_tokens)} dims. Received {len(input_shape)}-dim tensor.\")\n",
        "\n",
        "    if len(left_flat) != len(set(left_flat)):\n",
        "      raise ValueError(\"Invalid input, Pattern contains duplicate dimension\")\n",
        "\n",
        "    validate_tokens(left_flat)\n",
        "    validate_tokens(right_flat)\n",
        "\n",
        "    for item in left_flat:\n",
        "      if item not in right_flat:\n",
        "        raise ValueError(f\"Identifiers only on one side of expression: {item}\")\n",
        "\n",
        "    for ax in params:\n",
        "      if ax in left_flat or ax in right_flat:\n",
        "        continue\n",
        "      else:\n",
        "        raise ValueError(f\"Axes: {ax} has not been used in transformation\")\n",
        "\n",
        "    # Step 1 : Identify splits on left side\n",
        "    split_axes_inc = 0\n",
        "    for i, token in enumerate(left_tokens):\n",
        "        if isinstance(token, list):\n",
        "            steps.append({'op': 'split', 'axis': i + split_axes_inc, 'into': token})\n",
        "            split_axes_inc += len(token) - 1\n",
        "\n",
        "    # Step 2 : Compute common tokens and repeat ones\n",
        "    common_tokens = [tok for tok in right_flat if tok in left_flat]\n",
        "    repeat_tokens = []\n",
        "    for idx, tok in enumerate(right_flat):\n",
        "        if tok not in left_flat:\n",
        "          if tok in params:\n",
        "            repeat_tokens.append((tok, idx))\n",
        "          else:\n",
        "            raise ValueError(f\"Identifiers only on one side of expression: {tok}\")\n",
        "\n",
        "    # Step 3 : Compute transpose ordering for common tokens\n",
        "    transpose_order = [left_flat.index(tok) for tok in common_tokens]\n",
        "    if transpose_order != list(range(len(left_flat))):\n",
        "        steps.append({'op': 'transpose', 'order': transpose_order})\n",
        "\n",
        "    # Step 4 : Insert (repeat) new axes at their designated positions\n",
        "    for token, out_axis in repeat_tokens:\n",
        "        if token not in params:\n",
        "            raise ValueError(f\"Missing repetition count for token: {token}\")\n",
        "        steps.append({'op': 'repeat', 'token': token, 'count': params[token], 'axis': out_axis})\n",
        "\n",
        "    # Step 5 : Identify merge operations on the right side\n",
        "    number_merges = 0\n",
        "    for token in right_tokens:\n",
        "        if isinstance(token, list):\n",
        "            indices = [right_flat.index(tok) - number_merges for tok in token if tok in right_flat]\n",
        "            number_merges += len(token) - 1\n",
        "            steps.append({'op': 'merge', 'axes': indices, 'into': token})\n",
        "\n",
        "    return steps"
      ],
      "metadata": {
        "id": "gPoCjdtFrcii"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_split(x: np.ndarray, op: Dict, params: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Splits a merged axis into multiple axes.\n",
        "    \"\"\"\n",
        "    axis = op['axis']\n",
        "    tokens = op['into']\n",
        "    original_size = x.shape[axis]\n",
        "    sizes = []\n",
        "    for tok in tokens:\n",
        "        if tok not in params:\n",
        "            raise ValueError(f\"Missing size parameter for token: {tok}\")\n",
        "        sizes.append(params[tok])\n",
        "    if np.prod(sizes) != original_size:\n",
        "        raise ValueError(f\"Product of sizes {sizes} does not match dimension {original_size}\")\n",
        "\n",
        "    new_shape = list(x.shape[:axis]) + sizes + list(x.shape[axis+1:])\n",
        "    return np.reshape(x, new_shape)"
      ],
      "metadata": {
        "id": "WTRqdxUrrXmh"
      },
      "execution_count": 523,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_transpose(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transposes the axes according to the given order.\n",
        "    op contains the permutation order.\n",
        "    \"\"\"\n",
        "    return np.transpose(x, op['order'])"
      ],
      "metadata": {
        "id": "XjqxPdJHrVDE"
      },
      "execution_count": 524,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_repeat(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Inserts a new axis at the specified position and repeats it 'rep' times.\n",
        "    \"\"\"\n",
        "    axis = op['axis']\n",
        "    rep = op['count']\n",
        "    new_shape = list(x.shape)\n",
        "    new_shape.insert(axis, 1)\n",
        "    x_expanded = np.reshape(x, new_shape)\n",
        "    reps = [1] * len(new_shape)\n",
        "    reps[axis] = rep\n",
        "    return np.tile(x_expanded, reps)"
      ],
      "metadata": {
        "id": "UxpVXUVXrTHq"
      },
      "execution_count": 525,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_merge(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Merges (flattens) the axes specified in op['axes'] into a single axis.\n",
        "    op['axes'] is the list of axis indices getting merged.\n",
        "    \"\"\"\n",
        "    axes = op['axes']\n",
        "    if not axes:\n",
        "        return x\n",
        "    axes = sorted(axes)\n",
        "    merged_size = np.prod([x.shape[ax] for ax in axes])\n",
        "    new_shape = []\n",
        "    skip = set(axes)\n",
        "    for i in range(x.ndim):\n",
        "        if i == axes[0]:\n",
        "            new_shape.append(merged_size)\n",
        "        elif i in skip:\n",
        "            continue\n",
        "        else:\n",
        "            new_shape.append(x.shape[i])\n",
        "    return np.reshape(x, new_shape)"
      ],
      "metadata": {
        "id": "CEBiDb9PrRjy"
      },
      "execution_count": 526,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transformation(x: np.ndarray, steps: List[Dict], params: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies each transformation step in order to the input array.\n",
        "    \"\"\"\n",
        "    for step in steps:\n",
        "        op = step['op']\n",
        "        if op == 'split':\n",
        "            x = do_split(x, step, params)\n",
        "        elif op == 'transpose':\n",
        "            x = do_transpose(x, step)\n",
        "        elif op == 'repeat':\n",
        "            x = do_repeat(x, step)\n",
        "        elif op == 'merge':\n",
        "            x = do_merge(x, step)\n",
        "    return x"
      ],
      "metadata": {
        "id": "E3R7EwIBrPOG"
      },
      "execution_count": 527,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = \"(h1 h2) w -> h1 b1 (w h2)\"\n",
        "params = {'b1': 2, 'h1': 1, 'h2': 2}\n",
        "\n",
        "x = np.arange(2 * 3).reshape(2, 3)\n",
        "print(\"Input x shape:\", x.shape)\n",
        "print(\"x =\", x)\n",
        "\n",
        "left_tokens, right_tokens = parse_pattern(pattern)\n",
        "steps = determine_steps(left_tokens, right_tokens, x.shape, params)\n",
        "\n",
        "print(\"Parsed Left Tokens:\", left_tokens)\n",
        "print(\"Parsed Right Tokens:\", right_tokens)\n",
        "print(\"Transformation Steps:\")\n",
        "for step in steps:\n",
        "    print(step)\n",
        "\n",
        "y = apply_transformation(x, steps, params)\n",
        "print(\"Output shape:\", y.shape)\n",
        "print(\"y =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRflfaSKrNXR",
        "outputId": "405ab9ff-f7e0-4eb8-e272-11cf199e3f5b"
      },
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x shape: (2, 3)\n",
            "x = [[0 1 2]\n",
            " [3 4 5]]\n",
            "Parsed Left Tokens: [['h1', 'h2'], 'w']\n",
            "Parsed Right Tokens: ['h1', 'b1', ['w', 'h2']]\n",
            "Transformation Steps:\n",
            "{'op': 'split', 'axis': 0, 'into': ['h1', 'h2']}\n",
            "{'op': 'transpose', 'order': [0, 2, 1]}\n",
            "{'op': 'repeat', 'token': 'b1', 'count': 2, 'axis': 1}\n",
            "{'op': 'merge', 'axes': [2, 3], 'into': ['w', 'h2']}\n",
            "Output shape: (1, 2, 6)\n",
            "y = [[[0 3 1 4 2 5]\n",
            "  [0 3 1 4 2 5]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rearrange(tensor, pattern, **axes_lengths):\n",
        "\n",
        "    left_tokens, right_tokens = parse_pattern(pattern)\n",
        "\n",
        "    params2 = identify_implicit_axes(tensor.shape, pattern.split('->')[0], axes_lengths)\n",
        "\n",
        "    steps = determine_steps(left_tokens, right_tokens, tensor.shape, params2)\n",
        "\n",
        "    op = apply_transformation(tensor, steps, params2)\n",
        "\n",
        "    return op"
      ],
      "metadata": {
        "id": "y9i3_LLKOl8P"
      },
      "execution_count": 529,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import einops"
      ],
      "metadata": {
        "id": "2nfzWZRWRxUE"
      },
      "execution_count": 530,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Examples"
      ],
      "metadata": {
        "id": "rxIUjBk_niGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpose"
      ],
      "metadata": {
        "id": "bzeJtsGri51R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = np.random.randn(6, 3, 3)\n",
        "b1 = rearrange(a1, 'h w c -> w h c')\n",
        "c1 = einops.rearrange(a1, 'h w c -> w h c')\n",
        "# print(a1)\n",
        "# print(b1)\n",
        "# print(c1)\n",
        "print(np.array_equal(b1, c1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7-4ozfIeZOCI",
        "outputId": "9d1d0370-2852-4a05-d7f4-508538b1b0b7"
      },
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge"
      ],
      "metadata": {
        "id": "cU5HinUIi9N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a2 = np.random.randn(4, 4, 2)\n",
        "b2 = rearrange(a2, 'h w c -> (h w) c')\n",
        "c2 = einops.rearrange(a2, 'h w c -> (h w) c')\n",
        "# print(a2)\n",
        "# print(b2)\n",
        "# print(c2)\n",
        "print(np.array_equal(b2, c2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "55rL8XsbNkCT",
        "outputId": "68faa555-5228-4ac7-96ea-2b34281b317a"
      },
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a3 = np.random.randn(4, 4, 2)\n",
        "b3 = rearrange(a3, 'h w c -> (h w c)')\n",
        "c3 = einops.rearrange(a3, 'h w c -> (h w c)')\n",
        "# print(a3)\n",
        "# print(b3)\n",
        "# print(c3)\n",
        "print(np.array_equal(b3, c3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DIs8UQuwSDF3",
        "outputId": "105e7425-f720-494f-90a0-16e61fc39522"
      },
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpose and Merge"
      ],
      "metadata": {
        "id": "DLRuvs6RjC8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a4 = np.random.randn(3, 4, 4, 2)\n",
        "b4 = rearrange(a4, 'b h w c -> h (b w) c')\n",
        "c4 = einops.rearrange(a4, 'b h w c -> h (b w) c')\n",
        "# print(a4)\n",
        "# print(b4)\n",
        "# print(c4)\n",
        "print(np.array_equal(b4, c4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dfZPjgnYRl0o",
        "outputId": "8756d895-4aba-41e5-962a-c5d4e72718a0"
      },
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implicitly identify value of axes not given"
      ],
      "metadata": {
        "id": "mtVSt1lyjIXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a5 = np.random.randn(2, 3, 3)\n",
        "b5 = rearrange(a5, \"(b1 b2) h w -> b2 b1 h w\", b1=1)\n",
        "c5 = einops.rearrange(a5, \"(b1 b2) h w -> b2 b1 h w\", b1=1)\n",
        "# print(a5)\n",
        "# print(b5)\n",
        "# print(c5)\n",
        "print(np.array_equal(b5, c5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kISuNREO3CTt",
        "outputId": "e39f5b4d-8d86-4c5f-a448-5d2ef4c28f36"
      },
      "execution_count": 535,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a6 = np.random.randn(2, 3, 3)\n",
        "b6 = rearrange(a6, \"(b1 b2) h w -> (b1 h) (b2 w)\", b1=1)\n",
        "c6 = einops.rearrange(a6, \"(b1 b2) h w -> (b1 h) (b2 w)\", b1=1)\n",
        "# print(a6)\n",
        "# print(b6)\n",
        "# print(c6)\n",
        "print(np.array_equal(b6, c6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cS-hTvIx7J8i",
        "outputId": "d48b3348-13aa-449e-ed57-cdfe558e0bd4"
      },
      "execution_count": 536,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis handling and repeat"
      ],
      "metadata": {
        "id": "13O1m3tnjSwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a7 = np.random.rand(4, 1)\n",
        "b7 = einops.repeat(a7, '... -> ... c', c=2)\n",
        "c7 = rearrange(a7, '... -> ... c', c=2)\n",
        "#print(a7)\n",
        "# print(b7)\n",
        "# print(c7)\n",
        "print(np.array_equal(b7, c7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6HrwV3cHV8u2",
        "outputId": "c8576a37-a138-4c62-dfe2-d5d3b4ebddeb"
      },
      "execution_count": 537,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a8 = np.random.rand(2, 6)\n",
        "b8 = rearrange(a8, '... -> c ...', c=3)\n",
        "c8 = einops.repeat(a8, '... -> c ...', c=3)\n",
        "#print(a8)\n",
        "# print(b8)\n",
        "# print(c8)\n",
        "print(np.array_equal(b8, c8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8L_ZP7830hX",
        "outputId": "c521d7fd-517d-40ab-a4b3-d99cb3f388de",
        "collapsed": true
      },
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis handling and merge"
      ],
      "metadata": {
        "id": "nVJNf-2DjojN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a9 = np.random.rand(6, 3, 4, 2)\n",
        "b9 = rearrange(a9, '... w c -> ... (w c)')\n",
        "c9 = einops.rearrange(a9, '... w c -> ... (w c)')\n",
        "#print(a9)\n",
        "# print(b9)\n",
        "# print(c9)\n",
        "print(np.array_equal(b9, c9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dNA7xfoD_RIR",
        "outputId": "4608b4b4-0e8b-4f9c-e508-a8b1e70b4ff3"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis, merge and repeat"
      ],
      "metadata": {
        "id": "Ac_0DtyHjaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a10 = np.random.randn(2, 26, 26, 3)\n",
        "b10 = rearrange(a10, 'b ... -> b (...)')\n",
        "c10 = einops.repeat(a10, 'b ... -> b (...)')\n",
        "#print(a10)\n",
        "# print(b10)\n",
        "# print(c10)\n",
        "print(np.array_equal(b10, c10))"
      ],
      "metadata": {
        "id": "ZyW3qCR9_liU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067f74a1-99d5-40d8-fcfc-40fe668cf165",
        "collapsed": true
      },
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split"
      ],
      "metadata": {
        "id": "9H9tCGAjjwVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a11 = np.random.randn(3, 4)\n",
        "b11 = rearrange(a11, 'h (w1 w2) -> h w1 w2', w1=2, w2=2)\n",
        "c11 = einops.rearrange(a11, 'h (w1 w2) -> h w1 w2', w1=2, w2=2)\n",
        "#print(a11)\n",
        "# print(b11)\n",
        "# print(c11)\n",
        "print(np.array_equal(b11, c11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a90_OTq-r8FU",
        "outputId": "5a6de599-3b13-4a62-8305-18c5c79eb3cf"
      },
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat"
      ],
      "metadata": {
        "id": "lS7sCXHHjvBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a12 = np.random.rand(3, 4)\n",
        "b12 = rearrange(a12, 'h w -> h c w', c=3)\n",
        "c12 = einops.repeat(a12, 'h w -> h c w', c=3)\n",
        "#print(a12)\n",
        "# print(b12)\n",
        "# print(c12)\n",
        "print(np.array_equal(b12, c12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IU91POXJ-VR8",
        "outputId": "6bcc160d-9613-4db1-e737-637154a28848"
      },
      "execution_count": 542,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a13 = np.random.randn(2, 3)\n",
        "b13 = rearrange(a13, \"h w -> h b1 w\", b1=2)\n",
        "c13 = einops.repeat(a13, \"h w -> h b1 w\", b1=2)\n",
        "# print(a13)\n",
        "# print(b13)\n",
        "# print(c13)\n",
        "print(np.array_equal(b13, c13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRql60Ys1nl",
        "outputId": "db358245-eb91-4320-f705-7b13fab62570"
      },
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat and Merge"
      ],
      "metadata": {
        "id": "W-GbjE0rj_FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a14 = np.random.rand(3, 2)\n",
        "b14 = rearrange(a14, 'h w -> h (w c)', c=3)\n",
        "c14 = einops.repeat(a14, 'h w -> h (w c)', c=3)\n",
        "#print(a14)\n",
        "# print(b14)\n",
        "# print(b14)\n",
        "print(np.array_equal(b14, b14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TBcSx_dA-Y7C",
        "outputId": "6a01d199-52d9-494e-8f44-56e6040c14c4"
      },
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mad designer gallery, inspired from the einops library"
      ],
      "metadata": {
        "id": "hOFY9ik3OI0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_1 = np.random.randn(2, 3, 3, 1)\n",
        "c_1 = einops.rearrange(a_1, \"(b1 b2) h w ... -> (b1 h) (b2 w) ...\", b1=1)\n",
        "b_1 = rearrange(a_1, \"(b1 b2) h w ... -> (b1 h) (b2 w) ...\", b1=1)\n",
        "# print(a_1)\n",
        "# print(b_1)\n",
        "# print(c_1)\n",
        "print(np.array_equal(b_1, c_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bHPbOPYEOUCV",
        "outputId": "f565780a-8ae0-492e-8919-9dbbf71d47cf"
      },
      "execution_count": 545,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_2 = np.random.randn(2, 3)\n",
        "b_2 = rearrange(a_2, \"(h1 h2) w -> h1 b1 (w h2)\", b1=2, h1=1, h2=2)\n",
        "c_2 = einops.repeat(a_2, \"(h1 h2) w -> h1 b1 (w h2)\", b1=2, h1=1, h2=2)\n",
        "print(np.array_equal(b_2, c_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqwnvaxUt0KN",
        "outputId": "28ebaa46-93e7-4ed1-905c-08e178b76e10"
      },
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_3 = np.random.randn(2, 4, 8, 1)\n",
        "c_3 = einops.rearrange(a_3, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "b_3 = rearrange(a_3, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "print(np.array_equal(b_3, c_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV_RKQNdKfvl",
        "outputId": "10c310bf-deb9-4465-d604-a24e3f8ea1b3"
      },
      "execution_count": 547,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ims = np.random.randn(6, 96, 96, 3)"
      ],
      "metadata": {
        "id": "skBLxPX8OWkA"
      },
      "execution_count": 548,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md1 = rearrange(ims, \"(b1 b2) h w c -> (h b1) (w b2) c \", b1=2)\n",
        "ans1 = einops.rearrange(ims, \"(b1 b2) h w c -> (h b1) (w b2) c \", b1=2)\n",
        "print(np.array_equal(md1, ans1))\n",
        "\n",
        "md2 = rearrange(ims, \"(b1 b2) h w c -> (h b1) (b2 w) c\", b1=2)\n",
        "ans2 = einops.rearrange(ims, \"(b1 b2) h w c -> (h b1) (b2 w) c\", b1=2)\n",
        "print(np.array_equal(md2, ans2))\n",
        "\n",
        "md3 = rearrange(ims, \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\", h2=8, w2=8)\n",
        "ans3 = einops.rearrange(ims, \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\", h2=8, w2=8)\n",
        "print(np.array_equal(md3, ans3))\n",
        "\n",
        "md4 = rearrange(ims, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "ans4 = einops.rearrange(ims, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "print(np.array_equal(md4, ans4))\n",
        "\n",
        "md5 = rearrange(ims, \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\", h1=3, w1=3, b2=3)\n",
        "ans5 = einops.rearrange(ims, \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\", h1=3, w1=3, b2=3)\n",
        "print(np.array_equal(md5, ans5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA3kV_lxONDq",
        "outputId": "0514e09b-b5df-477c-e91e-38ae7ec4cb9a"
      },
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A few error handling cases"
      ],
      "metadata": {
        "id": "cmYgBD8goZ54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error handling of invalid axis names"
      ],
      "metadata": {
        "id": "5_7V42BXkjc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_p = np.random.randn(6, 3, 3)\n",
        "try:\n",
        "  rearrange(n_p, 'h... w c -> w h... (c k)', k=2)\n",
        "except ValueError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufIieI30X03I",
        "outputId": "617893cf-0a1c-4fd8-8c7c-2875b0d97741"
      },
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid axis identifier: 'h...'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate dimension error handling"
      ],
      "metadata": {
        "id": "-ErRwgzPjW15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import EinopsError"
      ],
      "metadata": {
        "id": "Zp-LdKWW288u"
      },
      "execution_count": 551,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae1 = np.random.rand(4, 3, 2)\n",
        "try:\n",
        "  be1 = rearrange(ae1, 'b b h -> b h b')\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce1 = einops.rearrange(ae1, 'b b h -> b h b')\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZR52l912w05",
        "outputId": "5b2c053c-e7d8-4e7e-d66b-e355565f5f92"
      },
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid input, Pattern contains duplicate dimension\n",
            " Error while processing rearrange-reduction pattern \"b b h -> b h b\".\n",
            " Input tensor shape: (4, 3, 2). Additional info: {}.\n",
            " Indexing expression contains duplicate dimension \"b\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error handling of axes not specified or not interpretable"
      ],
      "metadata": {
        "id": "DPgmdE3Yjd1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae2 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be2 = rearrange(ae2, '... w c -> ... w1 (w2 c)', w1 = 2, w2 = 2)\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce2 = einops.rearrange(ae2, '... w c -> ... w1 (w2 c)', w1 = 2, w2 = 2)\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jBXXy3eOmzKn",
        "outputId": "20ba3a00-b3eb-4ac0-802a-a26f90bf6767"
      },
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identifiers only on one side of expression: w\n",
            " Error while processing rearrange-reduction pattern \"... w c -> ... w1 (w2 c)\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {'w1': 2, 'w2': 2}.\n",
            " Identifiers only on one side of expression (should be on both): {'w2', 'w1', 'w'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ae3 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be3 = rearrange(ae3, 'b h w c -> b h ((w c))', w1 = 2, w2 = 2)\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce3 = einops.rearrange(ae3, 'b h w c -> b h w c)', w1 = 2, w2 = 2)\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhV0UcZmauB",
        "outputId": "527ca6eb-9362-4626-a39b-2e9e06cd9f74"
      },
      "execution_count": 554,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid axis identifier: '((w'\n",
            " Error while processing rearrange-reduction pattern \"b h w c -> b h w c)\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {'w1': 2, 'w2': 2}.\n",
            " Brackets are not balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invalid ellipsis sequence handling"
      ],
      "metadata": {
        "id": "2R_bMqka08Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae4 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be4 = rearrange(ae4, 'b ... c -> c .. b')\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce4 = einops.rearrange(ae4, 'b ... c -> c .. b')\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "0OKXzb5soiYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9ba6cf-62f5-474c-c7aa-741a1278c0fc"
      },
      "execution_count": 555,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid ellipsis sequence encountered: ..\n",
            " Error while processing rearrange-reduction pattern \"b ... c -> c .. b\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {}.\n",
            " Expression may contain dots only inside ellipsis (...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ae5 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be5 = rearrange(ae5, 'b . c -> c ... b')\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce5 = einops.rearrange(ae5, 'b . c -> c ... b')\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8KhEDFhyldj",
        "outputId": "175190fa-be2b-47e6-fc44-43d5d81833fa"
      },
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid ellipsis sequence encountered: .\n",
            " Error while processing rearrange-reduction pattern \"b . c -> c ... b\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {}.\n",
            " Expression may contain dots only inside ellipsis (...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ae6 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be6 = rearrange(ae6, 'h w c -> c h w')\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce6 = einops.rearrange(ae6, 'h w c -> c h w')\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f0ZjWZN1Mm_",
        "outputId": "414d1c20-dfcc-4e01-dae6-e1429fb1135d"
      },
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrong shape: expected 3 dims. Received 4-dim tensor.\n",
            " Error while processing rearrange-reduction pattern \"h w c -> c h w\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {}.\n",
            " Wrong shape: expected 3 dims. Received 4-dim tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_3Fh8H52Bka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}