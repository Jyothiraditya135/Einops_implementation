{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqourIHNK518pzvxnho7tF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyothiraditya135/Einops_implementation/blob/main/Einops_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The implementation"
      ],
      "metadata": {
        "id": "IdPatfpccg2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary imports\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Union, Tuple, Dict"
      ],
      "metadata": {
        "id": "EKny69WCqujn"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_implicit_axes(input_shape: List[int],\n",
        "                           left_str: str,\n",
        "                           params: Dict[str, int]) -> Dict[str, int] :\n",
        "    \"\"\"\n",
        "    The function identifies axes that are to be inferred from the shape of the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    left_dim_ltrs = re.findall(r'\\(.*?\\)|\\S+', left_str)\n",
        "\n",
        "    map_ltrs_dims = {}\n",
        "    for ax in params:\n",
        "        map_ltrs_dims[ax] = params[ax]\n",
        "\n",
        "    ell_len = 0\n",
        "\n",
        "    for i, a in enumerate(left_dim_ltrs):\n",
        "\n",
        "        i = i + ell_len\n",
        "\n",
        "        if a in map_ltrs_dims.keys():\n",
        "          raise ValueError(f\"Indexing expression contains duplicate dimension {a}\")\n",
        "\n",
        "        if a.startswith('('):\n",
        "          a = a.strip('()').split()\n",
        "          missing_ltr = None\n",
        "          prod = 1\n",
        "\n",
        "          for key in a:\n",
        "            if '(' in key or ')' in key:\n",
        "                raise ValueError(\"Brackets inside brackets not allowed\")\n",
        "            if key not in params:\n",
        "              missing_ltr = key\n",
        "            else:\n",
        "              prod *= params[key]\n",
        "\n",
        "          if missing_ltr is not None:\n",
        "              missing_dim = input_shape[i] // prod\n",
        "              map_ltrs_dims[missing_ltr] = missing_dim\n",
        "\n",
        "    return map_ltrs_dims"
      ],
      "metadata": {
        "id": "FT8q9ldw66t3"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_parse(pattern: str) -> List[str]:\n",
        "\n",
        "    parsed = re.findall(r\"\\([^()]+\\)|\\S+\", pattern)\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    for el in parsed:\n",
        "        if el.startswith(\"(\") and el.endswith(\")\"):\n",
        "            tokens.append(el[1:-1].split())\n",
        "        else:\n",
        "            tokens.append(el)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "gAqBM3qxrGif"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(tokens: List[str]) -> List[str]:\n",
        "    flat = []\n",
        "    for token in tokens:\n",
        "        if isinstance(token, list):\n",
        "            flat.extend(token)\n",
        "        else:\n",
        "            flat.append(token)\n",
        "    return flat"
      ],
      "metadata": {
        "id": "k_4rnHCNrgZR"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def substitute_ellipsis(flat_tokens: List[str], rank: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    If an ellipsis (\"...\") is present in the flat token list, substitute it with placeholder tokens.\n",
        "    For example, if rank = 5 and there are 2 explicit tokens, then the ellipsis is replaced by 3 tokens: [_e0, _e1, _e2]\n",
        "    \"\"\"\n",
        "\n",
        "    if flat_tokens.count('...') > 1:\n",
        "        raise ValueError(\"More than one ellipsis in pattern!\")\n",
        "\n",
        "    if \"...\" in flat_tokens:\n",
        "\n",
        "        pos = flat_tokens.index(\"...\")\n",
        "        other_toks = [tok for tok in flat_tokens if tok != \"...\"]\n",
        "        num_placeholders = rank - len(other_toks)\n",
        "\n",
        "        if num_placeholders < 0:\n",
        "            raise ValueError(\"More explicit tokens than tensor rank!\")\n",
        "\n",
        "        placeholders = [f\"_e{i}\" for i in range(num_placeholders)]\n",
        "\n",
        "        return (flat_tokens[:pos] + placeholders + flat_tokens[pos+1:]), placeholders\n",
        "\n",
        "    return flat_tokens, []"
      ],
      "metadata": {
        "id": "_D3YGaq1u-49"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_axis_name(name: str) -> bool:\n",
        "    return re.fullmatch(r\"[a-zA-Z_][a-zA-Z0-9_]*\", name)\n",
        "\n",
        "def validate_tokens(tokens: List[str]):\n",
        "    for token in tokens:\n",
        "        if not is_valid_axis_name(token):\n",
        "            raise ValueError(f\"Invalid axis identifier: '{token}'\")"
      ],
      "metadata": {
        "id": "5jF1AoWpbQhP"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_pattern(pattern: str) -> Tuple[List[str], List[str]]:\n",
        "\n",
        "    if '->' not in pattern:\n",
        "        raise ValueError(\"Pattern must contain '->'\")\n",
        "\n",
        "    left_str, right_str = pattern.split(\"->\")\n",
        "\n",
        "    left_tokens = tokenize_and_parse(left_str.strip())\n",
        "    right_tokens = tokenize_and_parse(right_str.strip())\n",
        "\n",
        "    return left_tokens, right_tokens"
      ],
      "metadata": {
        "id": "PHlRvMCOre0y"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_steps(left_tokens: List[str],\n",
        "                    right_tokens: List[str],\n",
        "                    input_shape: List[int],\n",
        "                    params: Dict[str, int]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    The function helps determine the steps to be taken based on the parsed pattern, to reach the required output.\n",
        "\n",
        "    Steps (applied in order):\n",
        "      1. Split (de-merge) operations from groups on the left.\n",
        "      2. Transpose of the \"common\" tokens to match the order in the right side.\n",
        "      3. Repeat (insertion) operations for tokens that exist on the right but not the left.\n",
        "         The step now includes the output axis at which to insert the new axis.\n",
        "      4. Merge operations for grouped tokens on the right.\n",
        "    \"\"\"\n",
        "\n",
        "    steps = []\n",
        "    axes_after_split = []\n",
        "\n",
        "    if '...' in left_tokens:\n",
        "\n",
        "        left_tokens_mod, placeholders = substitute_ellipsis(left_tokens, rank=len(input_shape))\n",
        "\n",
        "        right_tokens_mod = []\n",
        "        for i, tok in enumerate(right_tokens):\n",
        "            if \"...\" in tok:\n",
        "                pos = i\n",
        "                if isinstance(tok, list):\n",
        "                    right_tokens_mod.extend(right_tokens[:pos])\n",
        "                    right_tokens_mod.append(placeholders)\n",
        "                    right_tokens_mod.extend(right_tokens[pos+1:])\n",
        "                else:\n",
        "                    right_tokens_mod = right_tokens[:pos] + placeholders + right_tokens[pos+1:]\n",
        "\n",
        "        left_flat = flatten(left_tokens_mod)\n",
        "        right_flat = flatten(right_tokens_mod)\n",
        "\n",
        "        left_tokens = left_tokens_mod\n",
        "        right_tokens = right_tokens_mod\n",
        "\n",
        "    else:\n",
        "        left_flat = flatten(left_tokens)\n",
        "        right_flat = flatten(right_tokens)\n",
        "\n",
        "    if(len(left_tokens) != len(input_shape)):\n",
        "        raise ValueError(f\"Wrong shape: expected {len(left_tokens)} dims. Received {len(input_shape)}-dim tensor.\")\n",
        "\n",
        "    if len(left_flat) != len(set(left_flat)):\n",
        "      raise ValueError(\"Invalid input, Pattern contains duplicate dimension\")\n",
        "\n",
        "    validate_tokens(left_flat)\n",
        "    validate_tokens(right_flat)\n",
        "\n",
        "    for item in left_flat:\n",
        "      if item not in right_flat:\n",
        "        raise ValueError(f\"Identifiers only on one side of expression: {item}\")\n",
        "\n",
        "    for ax in params:\n",
        "      if ax in left_flat or ax in right_flat:\n",
        "        continue\n",
        "      else:\n",
        "        raise ValueError(f\"Axes: {ax} has not been used in transformation\")\n",
        "\n",
        "    # Step 1 : Identify splits on left side\n",
        "    split_axes_inc = 0\n",
        "    for i, token in enumerate(left_tokens):\n",
        "        if isinstance(token, list):\n",
        "            steps.append({'op': 'split', 'axis': i + split_axes_inc, 'into': token})\n",
        "            split_axes_inc += len(token) - 1\n",
        "\n",
        "    # Step 2 : Compute common tokens and repeat ones\n",
        "    common_tokens = [tok for tok in right_flat if tok in left_flat]\n",
        "    repeat_tokens = []\n",
        "    for idx, tok in enumerate(right_flat):\n",
        "        if tok not in left_flat:\n",
        "          if tok in params:\n",
        "            repeat_tokens.append((tok, idx))\n",
        "          else:\n",
        "            raise ValueError(f\"Identifiers only on one side of expression: {tok}\")\n",
        "\n",
        "    # Step 3 : Compute transpose ordering for common tokens\n",
        "    transpose_order = [left_flat.index(tok) for tok in common_tokens]\n",
        "    if transpose_order != list(range(len(left_flat))):\n",
        "        steps.append({'op': 'transpose', 'order': transpose_order})\n",
        "\n",
        "    # Step 4 : Insert (repeat) new axes at their designated positions\n",
        "    for token, out_axis in repeat_tokens:\n",
        "        if token not in params:\n",
        "            raise ValueError(f\"Missing repetition count for token: {token}\")\n",
        "        steps.append({'op': 'repeat', 'token': token, 'count': params[token], 'axis': out_axis})\n",
        "\n",
        "    # Step 5 : Identify merge operations on the right side\n",
        "    number_merges = 0\n",
        "    for token in right_tokens:\n",
        "        if isinstance(token, list):\n",
        "            indices = [right_flat.index(tok) - number_merges for tok in token if tok in right_flat]\n",
        "            number_merges += len(token) - 1\n",
        "            steps.append({'op': 'merge', 'axes': indices, 'into': token})\n",
        "\n",
        "    return steps"
      ],
      "metadata": {
        "id": "gPoCjdtFrcii"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_split(x: np.ndarray, op: Dict, params: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Splits a merged axis into multiple axes.\n",
        "    \"\"\"\n",
        "    axis = op['axis']\n",
        "    tokens = op['into']\n",
        "    original_size = x.shape[axis]\n",
        "    sizes = []\n",
        "    for tok in tokens:\n",
        "        if tok not in params:\n",
        "            raise ValueError(f\"Missing size parameter for token: {tok}\")\n",
        "        sizes.append(params[tok])\n",
        "    if np.prod(sizes) != original_size:\n",
        "        raise ValueError(f\"Product of sizes {sizes} does not match dimension {original_size}\")\n",
        "\n",
        "    new_shape = list(x.shape[:axis]) + sizes + list(x.shape[axis+1:])\n",
        "    return np.reshape(x, new_shape)"
      ],
      "metadata": {
        "id": "WTRqdxUrrXmh"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_transpose(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transposes the axes according to the given order.\n",
        "    op contains the permutation order.\n",
        "    \"\"\"\n",
        "    return np.transpose(x, op['order'])"
      ],
      "metadata": {
        "id": "XjqxPdJHrVDE"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_repeat(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Inserts a new axis at the specified position and repeats it 'rep' times.\n",
        "    \"\"\"\n",
        "    axis = op['axis']\n",
        "    rep = op['count']\n",
        "    new_shape = list(x.shape)\n",
        "    new_shape.insert(axis, 1)\n",
        "    x_expanded = np.reshape(x, new_shape)\n",
        "    reps = [1] * len(new_shape)\n",
        "    reps[axis] = rep\n",
        "    return np.tile(x_expanded, reps)"
      ],
      "metadata": {
        "id": "UxpVXUVXrTHq"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_merge(x: np.ndarray, op: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Merges (flattens) the axes specified in op['axes'] into a single axis.\n",
        "    op['axes'] is the list of axis indices getting merged.\n",
        "    \"\"\"\n",
        "    axes = op['axes']\n",
        "    if not axes:\n",
        "        return x\n",
        "    axes = sorted(axes)\n",
        "    merged_size = np.prod([x.shape[ax] for ax in axes])\n",
        "    new_shape = []\n",
        "    skip = set(axes)\n",
        "    for i in range(x.ndim):\n",
        "        if i == axes[0]:\n",
        "            new_shape.append(merged_size)\n",
        "        elif i in skip:\n",
        "            continue\n",
        "        else:\n",
        "            new_shape.append(x.shape[i])\n",
        "    return np.reshape(x, new_shape)"
      ],
      "metadata": {
        "id": "CEBiDb9PrRjy"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transformation(x: np.ndarray, steps: List[Dict], params: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies each transformation step in order to the input array.\n",
        "    \"\"\"\n",
        "    for step in steps:\n",
        "        op = step['op']\n",
        "        if op == 'split':\n",
        "            x = do_split(x, step, params)\n",
        "        elif op == 'transpose':\n",
        "            x = do_transpose(x, step)\n",
        "        elif op == 'repeat':\n",
        "            x = do_repeat(x, step)\n",
        "        elif op == 'merge':\n",
        "            x = do_merge(x, step)\n",
        "    return x"
      ],
      "metadata": {
        "id": "E3R7EwIBrPOG"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = \"(h1 h2) w -> h1 b1 (w h2)\"\n",
        "params = {'b1': 2, 'h1': 1, 'h2': 2}\n",
        "\n",
        "x = np.arange(2 * 3).reshape(2, 3)\n",
        "print(\"Input x shape:\", x.shape)\n",
        "print(\"x =\", x)\n",
        "\n",
        "left_tokens, right_tokens = parse_pattern(pattern)\n",
        "steps = determine_steps(left_tokens, right_tokens, x.shape, params)\n",
        "\n",
        "print(\"Parsed Left Tokens:\", left_tokens)\n",
        "print(\"Parsed Right Tokens:\", right_tokens)\n",
        "print(\"Transformation Steps:\")\n",
        "for step in steps:\n",
        "    print(step)\n",
        "\n",
        "y = apply_transformation(x, steps, params)\n",
        "print(\"Output shape:\", y.shape)\n",
        "print(\"y =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRflfaSKrNXR",
        "outputId": "2565bbdf-66c7-484f-9c8e-9d60ef208dfb"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x shape: (2, 3)\n",
            "x = [[0 1 2]\n",
            " [3 4 5]]\n",
            "Parsed Left Tokens: [['h1', 'h2'], 'w']\n",
            "Parsed Right Tokens: ['h1', 'b1', ['w', 'h2']]\n",
            "Transformation Steps:\n",
            "{'op': 'split', 'axis': 0, 'into': ['h1', 'h2']}\n",
            "{'op': 'transpose', 'order': [0, 2, 1]}\n",
            "{'op': 'repeat', 'token': 'b1', 'count': 2, 'axis': 1}\n",
            "{'op': 'merge', 'axes': [2, 3], 'into': ['w', 'h2']}\n",
            "Output shape: (1, 2, 6)\n",
            "y = [[[0 3 1 4 2 5]\n",
            "  [0 3 1 4 2 5]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rearrange(tensor, pattern, **axes_lengths):\n",
        "\n",
        "    left_tokens, right_tokens = parse_pattern(pattern)\n",
        "\n",
        "    params2 = identify_implicit_axes(tensor.shape, pattern.split('->')[0], axes_lengths)\n",
        "\n",
        "    steps = determine_steps(left_tokens, right_tokens, tensor.shape, params2)\n",
        "\n",
        "    op = apply_transformation(tensor, steps, params2)\n",
        "\n",
        "    return op"
      ],
      "metadata": {
        "id": "y9i3_LLKOl8P"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import einops"
      ],
      "metadata": {
        "id": "2nfzWZRWRxUE"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Examples"
      ],
      "metadata": {
        "id": "rxIUjBk_niGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpose"
      ],
      "metadata": {
        "id": "bzeJtsGri51R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = np.random.randn(6, 3, 3)\n",
        "b1 = rearrange(a1, 'h w c -> w h c')\n",
        "c1 = einops.rearrange(a1, 'h w c -> w h c')\n",
        "# print(a1)\n",
        "# print(b1)\n",
        "# print(c1)\n",
        "print(np.array_equal(b1, c1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7-4ozfIeZOCI",
        "outputId": "e14cb6fc-9928-4b67-b968-75a0ad00eb86"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge"
      ],
      "metadata": {
        "id": "cU5HinUIi9N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a2 = np.random.randn(4, 4, 2)\n",
        "b2 = rearrange(a2, 'h w c -> (h w) c')\n",
        "c2 = einops.rearrange(a2, 'h w c -> (h w) c')\n",
        "# print(a2)\n",
        "# print(b2)\n",
        "# print(c2)\n",
        "print(np.array_equal(b2, c2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "55rL8XsbNkCT",
        "outputId": "d6899907-895b-456f-bd9e-8cfaddbb2a1f"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a3 = np.random.randn(4, 4, 2)\n",
        "b3 = rearrange(a3, 'h w c -> (h w c)')\n",
        "c3 = einops.rearrange(a3, 'h w c -> (h w c)')\n",
        "# print(a3)\n",
        "# print(b3)\n",
        "# print(c3)\n",
        "print(np.array_equal(b3, c3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DIs8UQuwSDF3",
        "outputId": "e80ef135-95a2-4fdc-b231-d1554d0320a6"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpose and Merge"
      ],
      "metadata": {
        "id": "DLRuvs6RjC8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a4 = np.random.randn(3, 4, 4, 2)\n",
        "b4 = rearrange(a4, 'b h w c -> h (b w) c')\n",
        "c4 = einops.rearrange(a4, 'b h w c -> h (b w) c')\n",
        "# print(a4)\n",
        "# print(b4)\n",
        "# print(c4)\n",
        "print(np.array_equal(b4, c4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dfZPjgnYRl0o",
        "outputId": "611d43b5-77b0-453b-d96c-e05d5df386ec"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implicitly identify value of axes not given"
      ],
      "metadata": {
        "id": "mtVSt1lyjIXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a5 = np.random.randn(2, 3, 3)\n",
        "b5 = rearrange(a5, \"(b1 b2) h w -> b2 b1 h w\", b1=1)\n",
        "c5 = einops.rearrange(a5, \"(b1 b2) h w -> b2 b1 h w\", b1=1)\n",
        "# print(a5)\n",
        "# print(b5)\n",
        "# print(c5)\n",
        "print(np.array_equal(b5, c5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kISuNREO3CTt",
        "outputId": "138283ad-d9a5-467d-aecd-2e3ab1086dc6"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a6 = np.random.randn(2, 3, 3)\n",
        "b6 = rearrange(a6, \"(b1 b2) h w -> (b1 h) (b2 w)\", b1=1)\n",
        "c6 = einops.rearrange(a6, \"(b1 b2) h w -> (b1 h) (b2 w)\", b1=1)\n",
        "# print(a6)\n",
        "# print(b6)\n",
        "# print(c6)\n",
        "print(np.array_equal(b6, c6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cS-hTvIx7J8i",
        "outputId": "5e8f1e66-d7a8-4802-d455-0e816ca68d39"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis handling and repeat"
      ],
      "metadata": {
        "id": "13O1m3tnjSwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a7 = np.random.rand(4, 1)\n",
        "b7 = einops.repeat(a7, '... -> ... c', c=2)\n",
        "c7 = rearrange(a7, '... -> ... c', c=2)\n",
        "#print(a7)\n",
        "# print(b7)\n",
        "# print(c7)\n",
        "print(np.array_equal(b7, c7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6HrwV3cHV8u2",
        "outputId": "02db137f-a3f0-45c0-d1a8-30a392e3c5f8"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a8 = np.random.rand(2, 6)\n",
        "b8 = rearrange(a8, '... -> c ...', c=3)\n",
        "c8 = einops.repeat(a8, '... -> c ...', c=3)\n",
        "#print(a8)\n",
        "# print(b8)\n",
        "# print(c8)\n",
        "print(np.array_equal(b8, c8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8L_ZP7830hX",
        "outputId": "9599dec9-4105-467f-8e83-7cca0a314038",
        "collapsed": true
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis handling and merge"
      ],
      "metadata": {
        "id": "nVJNf-2DjojN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a9 = np.random.rand(6, 3, 4, 2)\n",
        "b9 = rearrange(a9, '... w c -> ... (w c)')\n",
        "c9 = einops.rearrange(a9, '... w c -> ... (w c)')\n",
        "#print(a9)\n",
        "# print(b9)\n",
        "# print(c9)\n",
        "print(np.array_equal(b9, c9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dNA7xfoD_RIR",
        "outputId": "57c21485-154e-4350-acc6-70b8e679fb9b"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellipsis, merge and repeat"
      ],
      "metadata": {
        "id": "Ac_0DtyHjaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a10 = np.random.randn(2, 26, 26, 3)\n",
        "b10 = rearrange(a10, 'b ... -> b (...)')\n",
        "c10 = einops.repeat(a10, 'b ... -> b (...)')\n",
        "#print(a10)\n",
        "# print(b10)\n",
        "# print(c10)\n",
        "print(np.array_equal(b10, c10))"
      ],
      "metadata": {
        "id": "ZyW3qCR9_liU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca59c6a6-1b90-4367-d99a-68e1e031e2b1",
        "collapsed": true
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split"
      ],
      "metadata": {
        "id": "9H9tCGAjjwVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a11 = np.random.randn(3, 4)\n",
        "b11 = rearrange(a11, 'h (w1 w2) -> h w1 w2', w1=2, w2=2)\n",
        "c11 = einops.rearrange(a11, 'h (w1 w2) -> h w1 w2', w1=2, w2=2)\n",
        "#print(a11)\n",
        "# print(b11)\n",
        "# print(c11)\n",
        "print(np.array_equal(b11, c11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a90_OTq-r8FU",
        "outputId": "e29f8599-1448-4678-9528-cbaf0dbec1c4"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat"
      ],
      "metadata": {
        "id": "lS7sCXHHjvBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a12 = np.random.rand(3, 4)\n",
        "b12 = rearrange(a12, 'h w -> h c w', c=3)\n",
        "c12 = einops.repeat(a12, 'h w -> h c w', c=3)\n",
        "#print(a12)\n",
        "# print(b12)\n",
        "# print(c12)\n",
        "print(np.array_equal(b12, c12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IU91POXJ-VR8",
        "outputId": "ba4f87ed-7607-41c2-8830-355d8864864b"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a13 = np.random.randn(2, 3)\n",
        "b13 = rearrange(a13, \"h w -> h b1 w\", b1=2)\n",
        "c13 = einops.repeat(a13, \"h w -> h b1 w\", b1=2)\n",
        "# print(a13)\n",
        "# print(b13)\n",
        "# print(c13)\n",
        "print(np.array_equal(b13, c13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRql60Ys1nl",
        "outputId": "e2c87c8c-026f-4be0-9323-400d58e15017"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat and Merge"
      ],
      "metadata": {
        "id": "W-GbjE0rj_FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a14 = np.random.rand(3, 2)\n",
        "b14 = rearrange(a14, 'h w -> h (w c)', c=3)\n",
        "c14 = einops.repeat(a14, 'h w -> h (w c)', c=3)\n",
        "#print(a14)\n",
        "# print(b14)\n",
        "# print(b14)\n",
        "print(np.array_equal(b14, b14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TBcSx_dA-Y7C",
        "outputId": "38661279-b717-426d-d4c0-9ae15b81d495"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mad designer gallery, inspired from the einops library"
      ],
      "metadata": {
        "id": "hOFY9ik3OI0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_1 = np.random.randn(2, 3, 3, 1)\n",
        "c_1 = einops.rearrange(a_1, \"(b1 b2) h w ... -> (b1 h) (b2 w) ...\", b1=1)\n",
        "b_1 = rearrange(a_1, \"(b1 b2) h w ... -> (b1 h) (b2 w) ...\", b1=1)\n",
        "# print(a_1)\n",
        "# print(b_1)\n",
        "# print(c_1)\n",
        "print(np.array_equal(b_1, c_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bHPbOPYEOUCV",
        "outputId": "fcda477f-7ec8-4a55-d01c-e500e88d0262"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_2 = np.random.randn(2, 3)\n",
        "b_2 = rearrange(a_2, \"(h1 h2) w -> h1 b1 (w h2)\", b1=2, h1=1, h2=2)\n",
        "c_2 = einops.repeat(a_2, \"(h1 h2) w -> h1 b1 (w h2)\", b1=2, h1=1, h2=2)\n",
        "print(np.array_equal(b_2, c_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqwnvaxUt0KN",
        "outputId": "0e3dbc1c-ce4a-4249-8a22-aa045a47cc52"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_3 = np.random.randn(2, 4, 8, 1)\n",
        "c_3 = einops.rearrange(a_3, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "b_3 = rearrange(a_3, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "print(np.array_equal(b_3, c_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV_RKQNdKfvl",
        "outputId": "89267580-cb48-45f0-a2cb-c119ff67c8da"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ims = np.random.randn(6, 96, 96, 3)"
      ],
      "metadata": {
        "id": "skBLxPX8OWkA"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md1 = rearrange(ims, \"(b1 b2) h w c -> (h b1) (w b2) c \", b1=2)\n",
        "ans1 = einops.rearrange(ims, \"(b1 b2) h w c -> (h b1) (w b2) c \", b1=2)\n",
        "print(np.array_equal(md1, ans1))\n",
        "\n",
        "md2 = rearrange(ims, \"(b1 b2) h w c -> (h b1) (b2 w) c\", b1=2)\n",
        "ans2 = einops.rearrange(ims, \"(b1 b2) h w c -> (h b1) (b2 w) c\", b1=2)\n",
        "print(np.array_equal(md2, ans2))\n",
        "\n",
        "md3 = rearrange(ims, \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\", h2=8, w2=8)\n",
        "ans3 = einops.rearrange(ims, \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\", h2=8, w2=8)\n",
        "print(np.array_equal(md3, ans3))\n",
        "\n",
        "md4 = rearrange(ims, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "ans4 = einops.rearrange(ims, \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\", h2=2, w2=2, w3=2, h3=2)\n",
        "print(np.array_equal(md4, ans4))\n",
        "\n",
        "md5 = rearrange(ims, \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\", h1=3, w1=3, b2=3)\n",
        "ans5 = einops.rearrange(ims, \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\", h1=3, w1=3, b2=3)\n",
        "print(np.array_equal(md5, ans5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA3kV_lxONDq",
        "outputId": "f6b62303-bfb8-481d-9244-d9967931b4da"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A few error handling cases"
      ],
      "metadata": {
        "id": "cmYgBD8goZ54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error handling of invalid axis names"
      ],
      "metadata": {
        "id": "5_7V42BXkjc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_p = np.random.randn(6, 3, 3)\n",
        "try:\n",
        "  rearrange(n_p, 'h... w c -> w h... (c k)', k=2)\n",
        "except ValueError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufIieI30X03I",
        "outputId": "1c824458-b42a-4463-b6b2-aa5796a874cb"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid axis identifier: 'h...'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate dimension error handling"
      ],
      "metadata": {
        "id": "-ErRwgzPjW15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import EinopsError"
      ],
      "metadata": {
        "id": "Zp-LdKWW288u"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae1 = np.random.rand(4, 3, 2)\n",
        "try:\n",
        "  be1 = rearrange(ae1, 'b b h -> b h b')\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce1 = einops.rearrange(ae1, 'b b h -> b h b')\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZR52l912w05",
        "outputId": "97b81045-a264-4e11-ee11-81e077aed86d"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid input, Pattern contains duplicate dimension\n",
            " Error while processing rearrange-reduction pattern \"b b h -> b h b\".\n",
            " Input tensor shape: (4, 3, 2). Additional info: {}.\n",
            " Indexing expression contains duplicate dimension \"b\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error handling of axes not specified or not interpretable"
      ],
      "metadata": {
        "id": "DPgmdE3Yjd1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ae2 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be2 = rearrange(ae2, '... w c -> ... w1 (w2 c)', w1 = 2, w2 = 2)\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce2 = einops.rearrange(ae2, '... w c -> ... w1 (w2 c)', w1 = 2, w2 = 2)\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jBXXy3eOmzKn",
        "outputId": "b1d564fd-2302-4262-8135-082ad06692c4"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identifiers only on one side of expression: w\n",
            " Error while processing rearrange-reduction pattern \"... w c -> ... w1 (w2 c)\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {'w1': 2, 'w2': 2}.\n",
            " Identifiers only on one side of expression (should be on both): {'w2', 'w1', 'w'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ae2 = np.random.rand(6, 3, 4, 2)\n",
        "try:\n",
        "  be2 = rearrange(ae2, 'b h w c -> b h ((w c))', w1 = 2, w2 = 2)\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "try:\n",
        "  ce2 = einops.rearrange(ae2, 'b h w c -> b h w c)', w1 = 2, w2 = 2)\n",
        "except EinopsError as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhV0UcZmauB",
        "outputId": "47e4615e-31b1-46f3-af24-824e19d6df33"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid axis identifier: '((w'\n",
            " Error while processing rearrange-reduction pattern \"b h w c -> b h w c)\".\n",
            " Input tensor shape: (6, 3, 4, 2). Additional info: {'w1': 2, 'w2': 2}.\n",
            " Brackets are not balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OKXzb5soiYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}